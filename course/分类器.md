# 分类器

+ [常见分类模型与算法](#4.1-常见分类模型与算法)
+ [线性判别法](#4.1-线性判别法(fisher))
+ [距离判别法](#4.2-距离判别法(knn))
+ [概率判别法](#4.3-概率判别法)
+ [贝叶斯信念网络](#4.4-贝叶斯信念网络(bayes-belief-network,bbn))
+ [决策树](#4.5-决策树(decision-tree))
+ [组合方法](#4.6-组合方法)
+ [支持向量机](#4.7-支持向量机(svm))

### 4.1 常见分类模型与算法
线性判别法
距离判别法
贝叶斯分类器
决策树
支持向量机(SVM)
神经网络 

### 4.1 线性判别法(Fisher)
MASS包与线性判别函数lda()
`R
library(MASS)
ld = lda(G ~ x1 + x2)
ld
`
分类判断
`R
z = predit(ld)
newG = z$class
newG
`
### 4.2 距离判别法(KNN)

### 4.3 概率判别法

#### 4.3.1 朴素贝叶斯分类
P(H|X)=P(X|H)P(H)/P(X)
P(X)=P(x1)P(x2)P(x3)...P(xn)
P(X|H)=P(x1|H)P(x2|H)P(x3|H)...P(xn|H)

#### 4.3.2 文本挖掘场景
网页自动分类
垃圾邮件判断
评论自动分析
通过用户访问内容判别用户喜好

#### 4.3.3 用户流失预警

##### 4.3.3.1 准备
足够详细足够长的客户历史数据
流失定义的确定
现有的管理考核体系
现有的挽留效果分析

##### 4.3.3.2 方法
建立预测模型
预测流失风险级别，预警有流失倾向的客户
针对客户特征，推断客户流失原因
设计有效的挽留方案
根据流失风险程度，有针对性地改善客户满意度

##### 4.3.3.3 应用

#### 4.3.4 用户标签系统
顶级客户
中高端客户
中端客户
低端客户


### 4.4 贝叶斯信念网络(Bayes Belief Network,BBN)
朴素贝叶斯分类器需要特征之间互相独立的强条件，制约了模型的适用
用有向无环图表达变量之间的依赖关系，变量用节点表示，依赖关系用边表示
祖先，父母和后代节点，贝叶斯网络中的一个节点，如果它的父母节点已知，则它条件独立于它的所有非后代节点
每个节点附带一个条件概率表(CPT)，表示该节点和父母节点的联系概率

#### 4.4.1 参考书
数据挖掘导论

#### 4.4.2 条件概率表(CPT)
如果节点X没有父母节点，则它的CPT之包含先验概率P(X)
如果节点X只有一个父母节点Y，则CPT中包含条件概率P(X|Y)
如果节点X有多个父母节点Y1,Y2,...,YK，则CPT中包含条件概率P(X|Y1,Y2,...,YK)

#### 4.4.3 贝叶斯推理
P(HD = Yes) = P(HD = Yes | E = a, D = b) P(E = A, D = B)

### 4.5 决策树(decision tree)
ID3算法
C4.5算法
CART算法(《classification and regression tree》)

rpart扩展包
`R
iris.rp = rpart(Species ~ ., data = iris, method = "class")
plot(iris.rp, uniform = T, branch = 0, margin = 0.1, main = "Classification Tree\nIris Species by Petal and Sepal Length")
text(iris.rp, use.n = T, fancy = T, col = "blue")
`
#### 4.5.1 算法的核心问题
该按什么样的次序来选择变量(属性)
最佳分离点(连续的情形)在哪

##### 4.5.1.2 ID3算法
Info(D):信息期望
Grain(A):信息增益

##### 4.5.1.3 C4.5算法
SplitInfo(D):分裂信息
GrainRatio(A):信息增益率
悲观剪枝法

##### 4.5.1.4 CART算法
Gini(D):基尼系数
Gini(A):基尼增益
后剪枝法

### 4.6 组合方法

#### 4.6.1 评估分类器效能
准确率、识别率
错误率、误分类率
敏感度、真正例率、召回率
特效性、真负利率
精度
F、F1、F分数精度和召回率的调和均值

#### 4.6.2 提升分类器准确率的组合方法
基于学习数据集抽样产生若干训练集
使用训练集产生若干分类器
每个分类器分别进行预测，通过简单选举多数，判定最终所属分类

#### 4.6.3 组合方法包括
装袋(bagging)
提升(boosting)
随机森林(random forest)

##### 4.6.3.1 Bagging
有放回抽样
自助样本(bootstrap)

##### 4.6.3.2 Adaboost
训练集中的元组被分配权重
迭代训练若干个分类器,在前一个分类器中被错误分类的元组,会被提高权重,使到它在后面建立的分类器里被更加关注

##### 4.6.3.3 Random Forest
randomForest
`R
model.forest <- randomForest(Species ~ ., data = iris)
pre.forest = predict(model.forest, iris)
table(pre.forest, iris$Species)
`
### 4.7 支持向量机(SVM)

#### 4.7.1 参考书
数据挖掘导论
凸优化

#### 4.7.2 支持向量机几何意义

##### 4.7.2.1 最大边缘超平面(MMH)

##### 4.7.2.2 转化为凸优化问题

##### 4.7.2.3 Karush-Kuhn-Tucker最优化条件(KKT条件)

##### 4.7.2.4 拉格朗日乘子法继续简化

##### 4.7.2.5 进一步简化为对偶问题

##### 4.7.2.6 松弛变量与惩罚函数

##### 4.7.2.7 在拉格朗日函数中使用核函数

#### 4.7.3 SMO算法(Sequential Minimal Optimization)

##### 4.7.3.1 原始论文
Sequential Minimal Optimization A Fast Algorithm for Training Support Vector Machines

##### 4.7.3.2 启发式选择方法

#### 4.7.4 R实验SVM
使用e1071包
`R
library(e1071)
model <- svm(Species ~ ., data = iris)
summary(model)
`
`R
pred <- predict(model, x)
# (same as:)
pred <- fitted(model)
table(pred, y)
`
`R
pred <- predict(model, x, decision.values = TRUE)
attr(pred, "decision.values")[1: 4,]
`
`R
polt(cmdscale(dist(iris[, -5]))), + col = as.integer(iris[, -5]), + pch = c("o", "+")[1: 150 %in% model$index + 1]
`
#### 4.7.5 libsvm

### 第22章 案例实战:python实现线性判别分析
111 python实现线性判别分析
112 求解得出降维结果

### 第12章 决策树算法
065 决策树原理概述
066 衡量标准-熵
067 决策树构造实例
068 信息增益率
069 决策树剪枝策略

### 第13章 案例实战:决策树sklearn实例
070 决策树复习
071 决策树涉及参数
072 数可视化与sklearn实例
073 sklearn参数选择模块

### 第14章 集成算法与随机森林
074 集成算法-随机森林
075 特征重要性衡量
076 提升模型
077 堆叠模型

### 第15章 泰坦尼克船员获救
078 数据介绍
079 数据预处理
080 回归模型进行预测
081 随机森林模型
082 特征选择

### 第16章 贝叶斯算法
083 贝叶斯算法概述
084 贝叶斯推导实例
085 贝叶斯拼写纠错实例
086 垃圾邮件过滤实例
087 贝叶斯实现拼写检查器

### 第17章 python文本数据分析
088 文本分析与关键词提取
089 相似度计算
090 新闻数据与任务简介
091 TF-IDF关键词提取
092 LDA建模
093 基于贝叶斯算法的新闻分类

### 第18章 支持向量机算法
094 支持向量机要解决的问题
095 距离与数据的定义
096 目标函数
097 目标函数求解
098 SVM求解实例
099 支持向量的作用
100 软间隔问题
101 SVM核变函数

### 第19章 SVM调参实例
102 sklearn求解支持向量机
103 SVM参数调节

### 第32章 xgboost集成算法
154 集成算法思想
155 xgboost基本原理
156 xgboost求解实例
157 xgboost安装
158 xgboost实例展示
159 adaboost算法概述
